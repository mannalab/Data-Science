{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projeto de Regressão - House Prices.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtSLP7UTK3HS"
      },
      "source": [
        "# Projeto de Estudo - _House Prices_ \n",
        "\n",
        "Estudo prático de Regressão de preço de casas (com _dataset California House Prices_);\n",
        "\n",
        "---\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1EOKP1UJ1ZAVzjUIaUP6t61dE84sJj3nO?usp=sharing)\n",
        "\n",
        "---\n",
        "\n",
        "[Leonichel Guimarães (PIBITI/CNPq-FA-UEM)](https://github.com/leonichel)\n",
        "\n",
        "Professora Linnyer Ruiz (orientadora)\n",
        "\n",
        "---\n",
        "\n",
        "Referência:\n",
        "\n",
        "GÉRON, Aurélien. _Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems_. 2. ed. O'Reilly Media, 2019.\n",
        "\n",
        "---\n",
        "\n",
        "Manna Team  |  UEM       |     CNPq\n",
        ":----------:|:----------:|:----------:|\n",
        "<img src=\"https://manna.team/_next/static/images/logo2-e283461cfa92b2105bfd67e8e530529e.png\" alt=\"Manna Team\" width=\"200\"/> | <img src=\"https://marcoadp.github.io/WebSiteDIN/img/logo-uem2.svg\" alt=\"UEM\" width=\"200\"/> | <img src=\"https://www.gov.br/cnpq/pt-br/canais_atendimento/identidade-visual/logo_cnpq.svg\" alt=\"CNPq\" width=\"200\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfA2bSLq2Jt0"
      },
      "source": [
        "## Leitura e exploração do banco de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxQeIJV12BX6"
      },
      "source": [
        "### Importando bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW5xUa8uK25i"
      },
      "source": [
        "# 1\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwJhxbN2yRyn"
      },
      "source": [
        "### Leitura"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11WVYiCOknr3"
      },
      "source": [
        "# DEMOSTRATIVO - NÃO EXECUTAR\n",
        "data = pd.read_csv(\"/content/sample_data/california_housing_train.csv\")\n",
        "dataTest = pd.read_csv(\"/content/sample_data/california_housing_train.csv\")\n",
        "data = data.append(dataTest)\n",
        "\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csdIlZ9e00TT"
      },
      "source": [
        "# 2\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/housing.csv\")\n",
        "\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viTgnwtLyUfe"
      },
      "source": [
        "### Exploração"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYRmXOGE7bts"
      },
      "source": [
        "data.info();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvgiIyFa8qcV"
      },
      "source": [
        "data[\"ocean_proximity\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTz2uoSN8vdR"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyXW2xxIAG5H"
      },
      "source": [
        "data.boxplot(['median_house_value'], figsize=(10, 10));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKN_yxsaATZg"
      },
      "source": [
        "y = data['ocean_proximity'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title('Ocean Proximity Summary')\n",
        "plt.ylabel('Number of Occurrences', fontsize=12)\n",
        "plt.xlabel('Ocean Proximity', fontsize=12)\n",
        "\n",
        "sns.barplot(y.index, y.values, alpha=0.7, palette=\"Set2\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J10tdwoa8wrd"
      },
      "source": [
        "data.hist(bins=50, figsize=(20,15))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXufAjUs8ofG"
      },
      "source": [
        "data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynRtztFqxrCd"
      },
      "source": [
        "### Criando um banco de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTs7Ms6r9-rW"
      },
      "source": [
        "# 3\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "housing = train.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttv6QwZRog8U"
      },
      "source": [
        "train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYZhUXm2okxc"
      },
      "source": [
        "test.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caaYR8Cgx4Wy"
      },
      "source": [
        "## Vizualização e análise de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mjum58teyeUl"
      },
      "source": [
        "### Vizualização geográfica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuzYiGRcAy5B"
      },
      "source": [
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1, figsize=(12, 8));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMYruMIeBXkB"
      },
      "source": [
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", \n",
        "           alpha=0.4, s=housing[\"population\"]/100, label=\"population\", \n",
        "           figsize=(12,8), c=\"median_house_value\", cmap=plt.get_cmap(\"rainbow\"), \n",
        "           colorbar=True)\n",
        "            \n",
        "plt.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4b-j6jFyiJE"
      },
      "source": [
        "Análise de correlação (coeficiente de _Pearson_)\n",
        "\n",
        "![Correlação](https://qph.fs.quoracdn.net/main-qimg-055d00ae63f6d33fc2d9c716af031f37.webp)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBX3oNWhB9LO"
      },
      "source": [
        "housing.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zGohv-dkO9N"
      },
      "source": [
        "housing.corr()[\"median_house_value\"].sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5Oa82_uqMUv"
      },
      "source": [
        "sns.heatmap(housing.corr(), square=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAvrRSviEmoC"
      },
      "source": [
        "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n",
        "\"housing_median_age\", \"latitude\"]\n",
        "\n",
        "pd.plotting.scatter_matrix(housing[attributes], figsize=(14, 9), alpha=0.1);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrLEjTMFys6c"
      },
      "source": [
        "### Testes com atributos combinados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hws6I030rbT2"
      },
      "source": [
        "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
        "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
        "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]\n",
        "\n",
        "housing.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YX1WEULBupJO"
      },
      "source": [
        "housing.corr()[\"median_house_value\"].sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHK7HHITgmUI"
      },
      "source": [
        "## Preparação dos dados para modelo de aprendizado\n",
        "\n",
        "Métodos de_SKLearn_ divididos em: \n",
        "\n",
        "* Estimadores - _estimators_ - _fit()_\n",
        "* Transformadores - _transformers_ - _transform()_\n",
        "* Preditores - _predictors_ - _predict()_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEqxGaIhgsk-"
      },
      "source": [
        "### Retornando valores de _housing_ e separando variáveis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDsY2Q7UfIib"
      },
      "source": [
        "#4\n",
        "housing = train.drop(\"median_house_value\", axis=1)\n",
        "housing_labels = train[\"median_house_value\"].copy()\n",
        "\n",
        "housing_num = housing.drop(\"ocean_proximity\", axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQM8z9ZfNKmT"
      },
      "source": [
        "housing.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7Z6qp2wNNsw"
      },
      "source": [
        "housing_num.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xolub4RXhBfZ"
      },
      "source": [
        "### Limpando banco (_data cleaning_)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vE-xDt_hhBY"
      },
      "source": [
        "# DEMONSTRATIVO - NÃO EXECUTAR\n",
        "\n",
        "# Remover valores nulos\n",
        "housing.dropna(subset=[\"total_bedrooms\"]) # Opção 1\n",
        "housing.drop(\"total_bedrooms\", axis=1) # Opção 2\n",
        "\n",
        "# Ou substituí-los por uma média dos valores\n",
        "median = housing[\"total_bedrooms\"].median() # Opção 3\n",
        "housing[\"total_bedrooms\"].fillna(median, inplace=True)\n",
        "\n",
        "# Ou substituir usando ferramentas do sklearn - Opção 4\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imputer = SimpleImputer(strategy=\"median\")\n",
        "imputer.fit(housing_num) # somente valores numéricos\n",
        "X = imputer.transform(housing_num) # vetor\n",
        "housing_tr = pd.DataFrame(X, columns=housing_num.columns) # adicionando em frame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXQ-GdExj-OZ"
      },
      "source": [
        "### Tratando dados não numéricos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiM7hG0FkFKw"
      },
      "source": [
        "# DEMONSTRATIVO - NÃO EXECUTAR\n",
        "\n",
        "# Transformar em lista de números (0, 1, 2, 3, ...); recomendado para poucas classes\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "ordinal_encoder = OrdinalEncoder() # cria encoder\n",
        "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat) # aplica o encoder\n",
        "\n",
        "housing_cat_encoded # lê o resultado\n",
        "ordinal_encoder.categories_ # lê os nomes das categorias\n",
        "\n",
        "# Transformar em vetores ([1 0 0 0], [0 1 0 0], ...); recomendado para muitas classes: profissões e CEPs, por exemplo\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "cat_encoder = OneHotEncoder() # cria encoder\n",
        "housing_cat_1hot = cat_encoder.fit_transform(housing_cat) # aplica o encoder\n",
        "\n",
        "housing_cat_1hot.toarray() # lê o resultado\n",
        "cat_encoder.categories_ # lê os nomes da categoria"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kve3ABo6oZxq"
      },
      "source": [
        "### Dimensionamento de recurso (_Feature Scaling_)\n",
        "\n",
        "Para banco de treinamento apenas;\n",
        "\n",
        "Dois métodos, pelo _SKLearn_: \n",
        "\n",
        "* Normalizar (_min-max scaling_): valores são re-escalados para um intervalor de 0 a 1 (ou outro intervalo); Equação: $X_{norm} = \\frac{X - X_{min}}{X_{max} - X_{min}}$\n",
        "\n",
        "* Padronizar (_standardization_): menos afetado por _outliers_, e não se regulariza para um intervalo específico. Equação: $X_{stand} = \\frac{X - X_{med}}{sd}$\n",
        "\n",
        "[Leitura adicional 1](https://towardsdatascience.com/normalization-vs-standardization-quantitative-analysis-a91e8a79cebf)\n",
        "\n",
        "[Leitura adicional 2](https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "558TYcVStbTq"
      },
      "source": [
        "# DEMONSTRATIVO - NÃO EXECUTAR\n",
        "\n",
        "# Normalização \n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "housing = scaler.fit_transform(housing)\n",
        "\n",
        "# Padronização\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "housing = scaler.fit_transform(housing)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vCegH_anAbR"
      },
      "source": [
        "### Transformações customizadas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVUTgEynnGId"
      },
      "source": [
        "# 5\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
        "\n",
        "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
        "    \n",
        "    def __init__(self, add_bedrooms_per_room = True):\n",
        "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self # nothing else to do\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
        "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
        "\n",
        "        if self.add_bedrooms_per_room:\n",
        "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
        "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
        "\n",
        "        else:\n",
        "            return np.c_[X, rooms_per_household, population_per_household]\n",
        "\n",
        "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
        "housing_extra_attribs = attr_adder.transform(housing.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKGlkP91xq1e"
      },
      "source": [
        "### Caminho de transformações (_Transformation Pipelines_)\n",
        "\n",
        "Extremamente importante: o caminho/ordem que os dados farão para se transformar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTfdk5C_x9Lp"
      },
      "source": [
        "# 6\n",
        "# Para numérico\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer    # data cleaning\n",
        "from sklearn.preprocessing import OneHotEncoder # para tratar dados textuais\n",
        "from sklearn.preprocessing import StandardScaler # feature scaling\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "    ('attribs_adder', CombinedAttributesAdder()),\n",
        "    ('std_scaler', StandardScaler()),\n",
        "    ])\n",
        "\n",
        "# housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
        "\n",
        "# Completo, para dados não numéricos e numéricos\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "num_attribs = list(housing_num)\n",
        "cat_attribs = [\"ocean_proximity\"]\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "    (\"num\", num_pipeline, num_attribs),\n",
        "    (\"cat\", OneHotEncoder(), cat_attribs),\n",
        "    ])\n",
        "\n",
        "housing_prepared = full_pipeline.fit_transform(housing)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S7_svjrN0V8"
      },
      "source": [
        "## Modelos de aprendizagem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSNmkRfFX0x7"
      },
      "source": [
        "### Avaliação\n",
        "\n",
        "Não tocamos ainda no banco de teste, vamos avaliar o modelo no banco de treinamento. E, quando tivermos certeza de nosso modelo, validamos-o com o banco de teste; Vamos usar 2 métodos:\n",
        "\n",
        "* Erro médio quadrado (_mean squared error_):\n",
        "* Validação cruzada (_cross-validation_)\n",
        "\n",
        "![Validação Cruzada](https://slideplayer.com.br/slide/356790/2/images/14/Valida%C3%A7%C3%A3o+Cruzada.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt6IC_CRX8W7"
      },
      "source": [
        "# 7\n",
        "# Funções para avaliação\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def mean_squared(labels, predictions):\n",
        "\n",
        "    lin_mse = mean_squared_error(labels, predictions)\n",
        "    lin_rmse = np.sqrt(lin_mse)\n",
        "    \n",
        "    print(\"Mean error:\", lin_rmse)\n",
        "\n",
        "def cross_val(model, predictions, labels):\n",
        "\n",
        "    scores = cross_val_score(model, predictions, labels, \n",
        "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
        "\n",
        "    tree_rmse_scores = np.sqrt(-scores)\n",
        "\n",
        "    print(\"Scores:\", tree_rmse_scores)\n",
        "    print(\"Mean:\", tree_rmse_scores.mean())\n",
        "    print(\"Standard deviation:\", tree_rmse_scores.std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNXa_7qMYXck"
      },
      "source": [
        "### Salvar modelos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN59s3hDYZzo"
      },
      "source": [
        "# 7\n",
        "# Salvar\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "def saveModel(model, name):\n",
        "\n",
        "    joblib.dump(model, name)\n",
        "\n",
        "# Ler\n",
        "# model = joblib.load(\"model.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTv3ebNLOGDk"
      },
      "source": [
        "### Mínimos quadrados (_ordinary least squares_)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0iviS-MNvxu"
      },
      "source": [
        "# Treino\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HaXoqr0OKZZ"
      },
      "source": [
        "# Predição\n",
        "some_data = housing.iloc[:5]\n",
        "some_labels = housing_labels.iloc[:5]\n",
        "some_data_prepared = full_pipeline.transform(some_data)\n",
        "\n",
        "print(\"Predictions:\", lin_reg.predict(some_data_prepared))\n",
        "print(\"Labels:\", list(some_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXIwR6F4PI3p"
      },
      "source": [
        "# Avaliação no banco de treinameto\n",
        "housing_predictions = lin_reg.predict(housing_prepared)\n",
        "\n",
        "mean_squared(housing_labels, housing_predictions)\n",
        "cross_val(lin_reg, housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxIC3HLYQOAp"
      },
      "source": [
        "### Regressão _Ridge_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n07V3HTQW5P"
      },
      "source": [
        "# Treino\n",
        "from sklearn import linear_model\n",
        "\n",
        "regRidge = linear_model.Ridge(alpha=.5)\n",
        "regRidge.fit(housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEKrPDX4Qypw"
      },
      "source": [
        "# Predição\n",
        "some_data = housing.iloc[:5]\n",
        "some_labels = housing_labels.iloc[:5]\n",
        "some_data_prepared = full_pipeline.transform(some_data)\n",
        "\n",
        "print(\"Predictions:\", regRidge.predict(some_data_prepared))\n",
        "print(\"Labels:\", list(some_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2e5mXGoQ48w"
      },
      "source": [
        "# Avaliação no banco de treinameto\n",
        "housing_predictions = regRidge.predict(housing_prepared)\n",
        "\n",
        "mean_squared(housing_labels, housing_predictions)\n",
        "cross_val(regRidge, housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFxwvDU3R5tq"
      },
      "source": [
        "### Regressão LASSO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqxCd0-iR8zn"
      },
      "source": [
        "# Treino\n",
        "from sklearn import linear_model\n",
        "\n",
        "regLasso = linear_model.Lasso(alpha=0.1)\n",
        "regLasso.fit(housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww0hV2PLSZ6H"
      },
      "source": [
        "# Predição\n",
        "some_data = housing.iloc[:5]\n",
        "some_labels = housing_labels.iloc[:5]\n",
        "some_data_prepared = full_pipeline.transform(some_data)\n",
        "\n",
        "print(\"Predictions:\", regLasso.predict(some_data_prepared))\n",
        "print(\"Labels:\", list(some_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tjpHzAdSd8N"
      },
      "source": [
        "# Avaliação no banco de treinameto\n",
        "housing_predictions = regLasso.predict(housing_prepared)\n",
        "\n",
        "mean_squared(housing_labels, housing_predictions)\n",
        "cross_val(regLasso, housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1vChuWuPuH9"
      },
      "source": [
        "### Árvores de desisão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V1BRsiJPs83"
      },
      "source": [
        "# Treino\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg = DecisionTreeRegressor()\n",
        "tree_reg.fit(housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foqy0NqjQA84"
      },
      "source": [
        "# Predição\n",
        "some_data = housing.iloc[:5]\n",
        "some_labels = housing_labels.iloc[:5]\n",
        "some_data_prepared = full_pipeline.transform(some_data)\n",
        "\n",
        "print(\"Predictions:\", tree_reg.predict(some_data_prepared))\n",
        "print(\"Labels:\", list(some_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kavGczTDRJ7G"
      },
      "source": [
        "# Avaliação no banco de treinameto\n",
        "housing_predictions = tree_reg.predict(housing_prepared)\n",
        "\n",
        "mean_squared(housing_labels, housing_predictions)\n",
        "cross_val(tree_reg, housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzs7WXs5XJrY"
      },
      "source": [
        "### Máquina de vetores de suporte (_SVM_)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7VEvIHbXRyQ"
      },
      "source": [
        "# Treino\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "svm_reg = SVR(kernel=\"linear\")\n",
        "svm_reg.fit(housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiJIky2ZXS0S"
      },
      "source": [
        "# Predição\n",
        "some_data = housing.iloc[:5]\n",
        "some_labels = housing_labels.iloc[:5]\n",
        "some_data_prepared = full_pipeline.transform(some_data)\n",
        "\n",
        "print(\"Predictions:\", svm_reg.predict(some_data_prepared))\n",
        "print(\"Labels:\", list(some_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxVYYQgAXVQ9"
      },
      "source": [
        "# Avaliação no banco de treinameto\n",
        "housing_predictions = svm_reg.predict(housing_prepared)\n",
        "\n",
        "mean_squared(housing_labels, housing_predictions)\n",
        "cross_val(svm_reg, housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkW3rc6QmpBJ"
      },
      "source": [
        "### Salvar e reustaurar modelos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHDKwXfEmJci"
      },
      "source": [
        "# Salvar\n",
        "saveModel(forest_reg, \"model.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kdwxt9APmnzw"
      },
      "source": [
        "# Ler\n",
        "model = joblib.load(\"model.pkl\")\n",
        "print(\"Predictions:\", model.predict(some_data_prepared))\n",
        "print(\"Labels:\", list(some_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox53Gfi5Xty9"
      },
      "source": [
        "## Aperfeiçoar modelos - ajuste-fino (_fine-tune of the models_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOw28TxL57Oz"
      },
      "source": [
        "### Busca por melhores modelos (_estimators_)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfO0VYOa6CkH"
      },
      "source": [
        "# DEMONSTRATIVO - NÃO EXECUTAR - MUITO LENTO\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn import tree\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        " \n",
        "pipeline = Pipeline(steps=[('estimator', LinearRegression())])\n",
        "\n",
        "params_grid = [{\n",
        "                'estimator':[LinearRegression()],\n",
        "                },\n",
        "                {\n",
        "                'estimator': [svm.SVR()],\n",
        "                'estimator__C': [1,2,3],\n",
        "                'estimator__epsilon': [0.1,0.2,0.3],\n",
        "                },\n",
        "                {\n",
        "                'estimator':[SGDRegressor()],\n",
        "                'estimator__max_iter':[500,1000,1500],\n",
        "               },\n",
        "                {\n",
        "                'estimator':[KNeighborsRegressor()],\n",
        "                'estimator__n_neighbors':[3,5,7],\n",
        "               },\n",
        "               {\n",
        "                'estimator':[tree.DecisionTreeRegressor()],\n",
        "                'estimator__criterion':['mse', 'poisson'],\n",
        "               },\n",
        "               {\n",
        "                'estimator':[GaussianNB()]\n",
        "               },\n",
        "              ]\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, params_grid, cv=5,\n",
        "                           scoring='neg_mean_squared_error',\n",
        "                           return_train_score=True)\n",
        "\n",
        "grid_search.fit(housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngaWMGuZECM7"
      },
      "source": [
        "# Exibindo resultado da melhor combinação de hiper-parâmetros\n",
        "grid_search.best_params_\n",
        "\n",
        "resultado:\n",
        "''' {'estimator': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
        "                     weights='uniform'), 'estimator__n_neighbors': 7} '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfWd8b4glHao"
      },
      "source": [
        "# Obtendo melhor modelo (estimator)\n",
        "grid_search.best_estimator_\n",
        "\n",
        "''' resultado:\n",
        "Pipeline(memory=None,\n",
        "         steps=[('estimator',\n",
        "                 KNeighborsRegressor(algorithm='auto', leaf_size=30,\n",
        "                                     metric='minkowski', metric_params=None,\n",
        "                                     n_jobs=None, n_neighbors=7, p=2,\n",
        "                                     weights='uniform'))],\n",
        "         verbose=False) '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4ufTG_hD5Wf"
      },
      "source": [
        "# Visualizando resultados\n",
        "cvres = grid_search.cv_results_\n",
        "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
        "    print(np.sqrt(-mean_score), params)\n",
        "\n",
        "''' resultado:\n",
        "67866.82839151102 {'estimator': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)}\n",
        "118493.77560936943 {'estimator': SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
        "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), 'estimator__C': 1, 'estimator__epsilon': 0.1}\n",
        "118493.77560936943 {'estimator': SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
        "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), 'estimator__C': 1, 'estimator__epsilon': 0.2}\n",
        "118493.77560936943 {'estimator': SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
        "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), 'estimator__C': 1, 'estimator__epsilon': 0.3}\n",
        "118201.75022645184 {'estimator': SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
        "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), 'estimator__C': 2, 'estimator__epsilon': 0.1}\n",
        "118201.75022645184 {'estimator': SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
        "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), 'estimator__C': 2, 'estimator__epsilon': 0.2}\n",
        "118201.75022645184 {'estimator': SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
        "(...)\n",
        "29964296.48683099 {'estimator': SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
        "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
        "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
        "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=None,\n",
        "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
        "             warm_start=False), 'estimator__max_iter': 1500}\n",
        "63796.83006909728 {'estimator': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "                    metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
        "                    weights='uniform'), 'estimator__n_neighbors': 3}\n",
        "61682.59497366035 {'estimator': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "                    metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
        "                    weights='uniform'), 'estimator__n_neighbors': 5}\n",
        "61160.46360411159 {'estimator': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "                    metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
        "                    weights='uniform'), 'estimator__n_neighbors': 7}\n",
        "(...)\n",
        "96416.18105983316 {'estimator': GaussianNB(priors=None, var_smoothing=1e-09)} '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfof5RxUVcTm"
      },
      "source": [
        "### Métodos com junção de modelos (_ensembles_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgff-MqEYywj"
      },
      "source": [
        "#### Floresta aleatória (_random forest_)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjUQ51P8VbQy"
      },
      "source": [
        "# Treinamento\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "forest_reg = RandomForestRegressor()\n",
        "reg.fit(housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJuyCKElWdmH"
      },
      "source": [
        "# Predição\n",
        "some_data = housing.iloc[:5]\n",
        "some_labels = housing_labels.iloc[:5]\n",
        "some_data_prepared = full_pipeline.transform(some_data)\n",
        "\n",
        "print(\"Predictions:\", forest_reg.predict(some_data_prepared))\n",
        "print(\"Labels:\", list(some_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLsI7bXsW5iC"
      },
      "source": [
        "# Avaliação no banco de treinameto\n",
        "housing_predictions = forest_reg.predict(housing_prepared)\n",
        "\n",
        "mean_squared(housing_labels, housing_predictions)\n",
        "cross_val(forest_reg, housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qm01w8VAsdA"
      },
      "source": [
        "#### Regressor _AdaBoosts_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yOy_5c4CUhg"
      },
      "source": [
        "# Treinamento\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "\n",
        "regr = AdaBoostRegressor(random_state=42, n_estimators=100)\n",
        "regr.fit(housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGS3LjZPCtzT"
      },
      "source": [
        "# Predição\n",
        "some_data = housing.iloc[:5]\n",
        "some_labels = housing_labels.iloc[:5]\n",
        "some_data_prepared = full_pipeline.transform(some_data)\n",
        "\n",
        "print(\"Predictions:\", regr.predict(some_data_prepared))\n",
        "print(\"Labels:\", list(some_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuJBkTyRC2q2"
      },
      "source": [
        "# Avaliação no banco de treinameto\n",
        "housing_predictions = regr.predict(housing_prepared)\n",
        "\n",
        "mean_squared(housing_labels, housing_predictions)\n",
        "cross_val(regr, housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z-jZGfIC6pe"
      },
      "source": [
        "#### Regressor _Gradient Boosting_ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8I0zRG_DC7J"
      },
      "source": [
        "# Treinamento\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "reg = GradientBoostingRegressor(random_state=0)\n",
        "reg.fit(housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJrlP6HFDiSO"
      },
      "source": [
        "# Predição\n",
        "some_data = housing.iloc[:5]\n",
        "some_labels = housing_labels.iloc[:5]\n",
        "some_data_prepared = full_pipeline.transform(some_data)\n",
        "\n",
        "print(\"Predictions:\", reg.predict(some_data_prepared))\n",
        "print(\"Labels:\", list(some_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPNOmwFVDkZj"
      },
      "source": [
        "# Avaliação no banco de treinameto\n",
        "housing_predictions = reg.predict(housing_prepared)\n",
        "\n",
        "mean_squared(housing_labels, housing_predictions)\n",
        "cross_val(reg, housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsBA0fMwFJNN"
      },
      "source": [
        "### Empilhamento _Stacking_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMVvvOqhJkq4"
      },
      "source": [
        "# Treinamento\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "\n",
        "estimators = [\n",
        "              ('kn', KNeighborsRegressor()),\n",
        "              ('gb', GradientBoostingRegressor(random_state=42))\n",
        "              ]\n",
        "\n",
        "reg = StackingRegressor(\n",
        "    estimators=estimators,\n",
        "    final_estimator=RandomForestRegressor(n_estimators=10,random_state=42))\n",
        "\n",
        "reg.fit(housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4iXPgIdKgdW"
      },
      "source": [
        "# Avaliação no banco de treinameto\n",
        "housing_predictions = reg.predict(housing_prepared)\n",
        "\n",
        "mean_squared(housing_labels, housing_predictions)\n",
        "cross_val(reg, housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zwk2ECrabyD"
      },
      "source": [
        "### Otimização de hiper-parâmetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2Z74Dntik5I"
      },
      "source": [
        "#### Busca por valores ótimos de hiper-parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJqhO0OOO19S"
      },
      "source": [
        "# 8\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = [\n",
        "    # tentativa com 12 (3×4) combinações de hiper-parâmetros\n",
        "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
        "    # e mais tentativa com 6 (2×3) combinações com bootstrap como False\n",
        "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
        "  ]\n",
        "\n",
        "forest_reg = RandomForestRegressor(random_state=42)\n",
        "# treina com 5 subconjuntos (folds), totalizando (12+6)*5 = 90 rodadas de treinamento \n",
        "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
        "                           scoring='neg_mean_squared_error',\n",
        "                           return_train_score=True)\n",
        "grid_search.fit(housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAYhRjF0eeig"
      },
      "source": [
        "# Exibindo resultado da melhor combinação de hiper-parâmetros\n",
        "grid_search.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NKnOCguehTe"
      },
      "source": [
        "# Obtendo melhor modelo (estimator)\n",
        "grid_search.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu1UhdGfelRt"
      },
      "source": [
        "# Visualizando resultados\n",
        "cvres = grid_search.cv_results_\n",
        "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
        "    print(np.sqrt(-mean_score), params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC8uuT9Weo_s"
      },
      "source": [
        "# Visualizando em tabela\n",
        "pd.DataFrame(grid_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpJl_Zp7irrB"
      },
      "source": [
        "#### Busca aleatória por valores ótimos de hiper-parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-78wcjpfsGW"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "param_distribs = {\n",
        "        'n_estimators': randint(low=1, high=200),\n",
        "        'max_features': randint(low=1, high=8),\n",
        "    }\n",
        "\n",
        "forest_reg = RandomForestRegressor(random_state=42)\n",
        "rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\n",
        "                                n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
        "rnd_search.fit(housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TK5EuOpgXeM"
      },
      "source": [
        "# Visualizando resultados\n",
        "cvres = rnd_search.cv_results_\n",
        "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
        "    print(np.sqrt(-mean_score), params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIY_WAc2Zt1d"
      },
      "source": [
        "### Extras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0NYVQohbLj-"
      },
      "source": [
        "#### Busca automática por melhores parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj7iJDmGbX30"
      },
      "source": [
        "# DEMONSTRATIVO - NÃO EXECUTAR\n",
        "\n",
        "param_grid = [{\n",
        "    'preparation__num__imputer__strategy': ['mean', 'median', 'most_frequent'],\n",
        "    'feature_selection__k': list(range(1, len(feature_importances) + 1))\n",
        "}]\n",
        "\n",
        "grid_search_prep = GridSearchCV(prepare_select_and_predict_pipeline, param_grid, cv=5,\n",
        "                                scoring='neg_mean_squared_error', verbose=2)\n",
        "grid_search_prep.fit(housing, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HKqVbRmTevt"
      },
      "source": [
        "#### Selecionando melhores atributos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KgdyxvATiER"
      },
      "source": [
        "# DEMONSTRATIVO - NÃO EXECUTAR\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "def indices_of_top_k(arr, k):\n",
        "    return np.sort(np.argpartition(np.array(arr), -k)[-k:])\n",
        "\n",
        "class TopFeatureSelector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, feature_importances, k):\n",
        "        self.feature_importances = feature_importances\n",
        "        self.k = k\n",
        "    def fit(self, X, y=None):\n",
        "        self.feature_indices_ = indices_of_top_k(self.feature_importances, self.k)\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        return X[:, self.feature_indices_]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVjgyyhYTpkc"
      },
      "source": [
        "# DEMONSTRATIVO - NÃO EXECUTAR\n",
        "\n",
        "k = 5\n",
        "top_k_feature_indices = indices_of_top_k(feature_importances, k)\n",
        "top_k_feature_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_5d30BKT51y"
      },
      "source": [
        "# DEMONSTRATIVO - NÃO EXECUTAR\n",
        "\n",
        "np.array(attributes)[top_k_feature_indices]\n",
        "sorted(zip(feature_importances, attributes), reverse=True)[:k]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJEMF8klU205"
      },
      "source": [
        "#### Caminho completo (_pipeline_ completo)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6nmEbDeU2hC"
      },
      "source": [
        "# DEMONSTRATIVO - NÃO EXECUTAR\n",
        "\n",
        "final_pipeline = Pipeline([\n",
        "    ('preparation', full_pipeline),\n",
        "    ('feature_selection', TopFeatureSelector(feature_importances, k)),\n",
        "    ('reg', RandomForestRegressor(max_features=k, n_estimators=180))\n",
        "])\n",
        "\n",
        "final_pipeline.fit(housing, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mbTmjszlk_Z"
      },
      "source": [
        "## Validação do modelo com banco de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9I2izpQluN7"
      },
      "source": [
        "# 9\n",
        "# Validação\n",
        "final_model = grid_search.best_estimator_\n",
        "\n",
        "X_test = test.drop(\"median_house_value\", axis=1)\n",
        "y_test = test[\"median_house_value\"].copy()\n",
        "\n",
        "X_test_prepared = full_pipeline.transform(X_test)\n",
        "\n",
        "final_predictions = final_model.predict(X_test_prepared)\n",
        "\n",
        "final_mse = mean_squared_error(y_test, final_predictions)\n",
        "final_rmse = np.sqrt(final_mse)\n",
        "final_rmse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y49KuhOGmEWH"
      },
      "source": [
        "# 10\n",
        "# Obtendo intervalo de confiança\n",
        "from scipy import stats\n",
        "\n",
        "confidence = 0.95\n",
        "squared_errors = (final_predictions - y_test) ** 2\n",
        "np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,\n",
        "                         loc=squared_errors.mean(),\n",
        "                         scale=stats.sem(squared_errors)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbzYxFeCaxL8"
      },
      "source": [
        "## Exportar modelo\n",
        "\n",
        "Nota: para chegar do início até esse modelo exportado, percorrer todas células enumeradas de 1 até 11. As demais células foram utilizadas para análises e criação de outros modelos, que não foram exportados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCgB5fTMa0SP"
      },
      "source": [
        "# 11 \n",
        "saveModel(final_model, \"Housing_RandomForest.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}